<!doctype html>
<html class="docs-version-current" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.6">
<title data-react-helmet="true">Using Calibration Sensor Data | Aria Data Tools</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://facebookresearch.github.io/Aria_data_tools/docs/howto/calibration/"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="Using Calibration Sensor Data | Aria Data Tools"><meta data-react-helmet="true" name="description" content="Introduction"><meta data-react-helmet="true" property="og:description" content="Introduction"><link data-react-helmet="true" rel="shortcut icon" href="/Aria_data_tools/img/fav_aria_icon.png"><link data-react-helmet="true" rel="canonical" href="https://facebookresearch.github.io/Aria_data_tools/docs/howto/calibration/"><link data-react-helmet="true" rel="alternate" href="https://facebookresearch.github.io/Aria_data_tools/docs/howto/calibration/" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://facebookresearch.github.io/Aria_data_tools/docs/howto/calibration/" hreflang="x-default"><link rel="stylesheet" href="/Aria_data_tools/assets/css/styles.7603c748.css">
<link rel="preload" href="/Aria_data_tools/assets/js/runtime~main.78e34e17.js" as="script">
<link rel="preload" href="/Aria_data_tools/assets/js/main.dd0e5fb6.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script>
<div style="display: none; text-align: center; background-color: white; color: black;" id="internaldocs-banner"></div><div id="__docusaurus">
<div><a href="#" class="skipToContent_1oUP">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Aria_data_tools/"><img src="/Aria_data_tools/img/glasses-solid.svg" alt="aria-research-kit-sdk Logo" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/Aria_data_tools/img/glasses-solid.svg" alt="aria-research-kit-sdk Logo" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"><b class="navbar__title">Aria Data Tools</b></a><a class="navbar__item navbar__link navbar__link--active" href="/Aria_data_tools/docs/overview/">Documentation</a><a href="https://about.facebook.com/realitylabs/projectaria/datasets" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>Aria Pilot Dataset<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><a href="https://about.facebook.com/realitylabs/projectaria/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>Project Aria<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/facebookresearch/aria_data_tools" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="react-toggle toggle_3Zt9 react-toggle--disabled"><div class="react-toggle-track" role="button" tabindex="-1"><div class="react-toggle-track-check"><span class="toggle_71bT">ðŸŒœ</span></div><div class="react-toggle-track-x"><span class="toggle_71bT">ðŸŒž</span></div><div class="react-toggle-thumb"></div></div><input type="checkbox" class="react-toggle-screenreader-only" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_31aa"><button class="clean-btn backToTopButton_35hR" type="button"><svg viewBox="0 0 24 24" width="28"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z" fill="currentColor"></path></svg></button><aside class="docSidebarContainer_3Kbt"><div class="sidebar_15mo"><nav class="menu thin-scrollbar menu_Bmed menuWithAnnouncementBar_2WvA"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" href="/Aria_data_tools/docs/overview/">Overview</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" href="/Aria_data_tools/docs/Install/">Install</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" href="/Aria_data_tools/docs/sensors-measurements/">Sensors and Measurements</a></li><li class="theme-doc-sidebar-item-category menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#">How to Use the Tools</a><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" tabindex="0" href="/Aria_data_tools/docs/howto/examples/">Examples</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" tabindex="0" href="/Aria_data_tools/docs/howto/dataprovider/">Accessing Sensor Data</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" tabindex="0" href="/Aria_data_tools/docs/howto/visualizing/">Visualize Sequences and Pre-Computed Camera Trajectory</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Aria_data_tools/docs/howto/calibration/">Using Calibration Sensor Data</a></li></ul></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#">Aria Pilot Dataset</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" href="/Aria_data_tools/docs/aria-vrs/">How Project Aria Uses VRS</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" href="/Aria_data_tools/docs/use-vrs/">Getting to Know and Use VRS</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" href="/Aria_data_tools/docs/faq/">FAQ</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" href="/Aria_data_tools/docs/citation-contribute/">Citation and Contributing</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" href="/Aria_data_tools/docs/license/">License</a></li></ul></nav></div></aside><main class="docMainContainer_3ufF"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_1lV3"><div class="docItemContainer_zt2Y"><article><div class="markdown"><header><h1>Using Calibration Sensor Data</h1></header><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="introduction"></a>Introduction<a class="hash-link" href="#introduction" title="Direct link to heading">#</a></h2><p>This page covers:</p><ul><li>General Project Aria device calibration principles</li><li>Python3 scripts for extrinsics and intrinsics</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="project-aria-device-calibration"></a>Project Aria device calibration<a class="hash-link" href="#project-aria-device-calibration" title="Direct link to heading">#</a></h2><p>Calibration data can be used to determine the 6DoF transformation between any pair of Project Aria device&#x27;s sensors.</p><p>Project Aria devices contain multiple types of sensors that are all calibrated when each device is manufactured. The calibration process derives intrinsic and extrinsic parameters (relative poses between sensors). This information is stored on every device and inserted into every <a href="/Aria_data_tools/docs/aria-vrs/">VRS</a> data file it records.</p><p>In Python, you can fetch this information from VRS and parse it into a data structure using the following code snippet:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">&gt;&gt;&gt; import pyark</span></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;&gt;&gt; reader = pyark.RecordFileReader()</span></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;&gt;&gt; reader.openFile(&#x27;./data/aria_unit_test_sequence_calib.vrs&#x27;)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">[ProgressLogger][INFO]: 26881.515: Opening diskfile file...0</span></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;&gt;&gt; deviceModel = pyark.DeviceModel.fromJson(pyark.getCalibrationFromVrsFile(reader))</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="sensors"></a>Sensors<a class="hash-link" href="#sensors" title="Direct link to heading">#</a></h2><p>Go to <a href="/Aria_data_tools/docs/sensors-measurements/">Sensors and Measurements</a> for information about Project Aria device sensors and how they are described in the tooling.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="calibration"></a>Calibration<a class="hash-link" href="#calibration" title="Direct link to heading">#</a></h2><p>In computer vision, camera calibration is managed by two sets of parameters:</p><ul><li><strong>Intrinsics</strong>: Parameters defining how 3D points project to the image plane (focal, principal point, distortions coefficients, and so on). Intrinsics parameters allow you to <em>project</em> 3D points in 2D and <em>unproject</em> 2D feature observations to 3D rays (bearing vectors).</li><li><strong>Extrinsics</strong>: Parameters defining where the camera is in space (Rotation|Translation). Extrinsics allow you to move world points to the camera coordinate system.</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="extrinsics"></a>Extrinsics<a class="hash-link" href="#extrinsics" title="Direct link to heading">#</a></h3><p>Extrinsic parameters are represented as a SE(3) matrix, that contains a rotation part (SO(3)) as a unit quaternion and a translation part as an R3 coordinate. To manipulate transformations such as relative pose between sensors, or re-projecting a 3D point from one sensor to another we use the <a href="https://github.com/strasdat/Sophus" target="_blank" rel="noopener noreferrer">Sophus library</a>.</p><p>In the code and the documentation throughout this project, we use the following notation:</p><ul><li><code>p_sensor</code> represents an R3 point in the local coordinate system of <code>sensor</code>. e.g. <code>p_slamLeft</code>.</li><li><code>T_sensor1_sensor2</code> represents a relative SE(3) transformation from <code>sensor2</code> frame to <code>sensor1</code> frame. An easy mnemonic is the chaining principle: <code>T_sensor1_sensor2 * T_sensor2_sensor3 * p_sensor3 = p_sensor1</code></li></ul><p>You can transform a 3D point from one sensor to the another one using the <code>transform()</code> operator:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">&gt;&gt;&gt; import numpy as np</span></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;&gt;&gt; p_slamLeft = np.array([3.0, 2.0, 1.0])</span></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;&gt;&gt; p_imuRight = deviceModel.transform(p_slamLeft, &#x27;camera-slam-left&#x27;, &#x27;imu-right&#x27;)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;&gt;&gt; p_imuRight</span></span><span class="token-line" style="color:#393A34"><span class="token plain">array([ 3.33343274, -1.41484796,  1.20512771])</span></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;&gt;&gt; deviceModel.transform(p_imuRight, &#x27;imu-right&#x27;, &#x27;camera-slam-left&#x27;)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">array([3., 2., 1.]) # as you see we retrieve the initial 3D point</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="intrinsics"></a>Intrinsics<a class="hash-link" href="#intrinsics" title="Direct link to heading">#</a></h3><p>Cameras can be configured to have a function that maps a 3D point in its local coordinate frame to the image pixel space. The parameters of this projection function are called the intrinsic parameter of a camera. All cameras on Project Aria devices are fisheye cameras. This means they are modeled by a spherical projection followed by additional distortion correction (rather than being modeled by a pinhole projection plus distortion).</p><p>For Project Aria devices, we use:</p><ul><li><a href="https://ieeexplore.ieee.org/document/1642666" target="_blank" rel="noopener noreferrer">Kannala-Brandt model</a> for eye tracking cameras</li><li>FisheyeRadTanThinPrism model for SLAM and RGB cameras</li></ul><p>You can perform the projection and un-projection operations using the following Python3 script:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">&gt;&gt;&gt; p_slamLeft = np.array([3.0, 2.0, 1.0])</span></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;&gt;&gt; uv_slamLeft = deviceModel.getCameraCalib(&#x27;camera-slam-left&#x27;).projectionModel.project(p_slamLeft)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;&gt;&gt; uv_slamLeft</span></span><span class="token-line" style="color:#393A34"><span class="token plain">array([583.48105528, 411.98136675])</span></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;&gt;&gt; deviceModel.getCameraCalib(&#x27;camera-slam-left&#x27;).projectionModel.unproject(uv_slamLeft)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">array([3., 2., 1.]) #return the corresponding bearing_vector (ray)</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>The IMU sensors use a linear rectification model for both accelerometers and gyroscopes to rectify an R3 point in its local coordinate system. The model includes a 3x3 rectification matrix A (correcting scale and non-orthogonality) and a 3x1 bias vector <code>b</code>.</p><p>To apply the rectification, use the Python3 scripts:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">&gt;&gt;&gt; p_imuLeft = np.array([3.0, 2.0, 1.0])</span></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;&gt;&gt; deviceModel.getImuCalib(&#x27;imu-left&#x27;).accel.rectify(p_imuLeft)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">array([2.93735023, 2.02130446, 0.87514154])`</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>This rectification process applies this formula:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">p_real = A.inv() * (p_raw - b)</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>When applied to accelerometer data, <code>p_raw</code> represents acceleration.  When applied to gyroscope data <code>p_raw</code>  represents angular velocity.</p></div></article><div class="margin-vert--lg"><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/Aria_data_tools/docs/howto/visualizing/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Â« Visualize Sequences and Pre-Computed Camera Trajectory</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/Aria_data_tools/docs/pilotdata/pilotdata-index/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Aria Pilot Dataset Overview Â»</div></a></div></nav></div></div></div><div class="col col--3"><div class="tableOfContents_35-E thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction" class="table-of-contents__link">Introduction</a></li><li><a href="#project-aria-device-calibration" class="table-of-contents__link">Project Aria device calibration</a></li><li><a href="#sensors" class="table-of-contents__link">Sensors</a></li><li><a href="#calibration" class="table-of-contents__link">Calibration</a><ul><li><a href="#extrinsics" class="table-of-contents__link">Extrinsics</a></li><li><a href="#intrinsics" class="table-of-contents__link">Intrinsics</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Learn</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/Aria_data_tools/docs/overview/">Documentation</a></li></ul></div><div class="col footer__col"><div class="footer__title">Project Aria</div><ul class="footer__items"><li class="footer__item"><a href="https://about.facebook.com/realitylabs/projectaria/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Introducing Project Aria<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://about.facebook.com/realitylabs/projectaria/datasets" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Aria Pilot Dataset<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">Responsible Innovation</div><ul class="footer__items"><li class="footer__item"><a href="https://about.facebook.com/realitylabs/responsible-innovation-principles/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Responsible Innovation Principles<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://about.facebook.com/realitylabs/projectaria/community-guidelines/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Project Aria Research Community Guidelines<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="margin-bottom--sm"><a href="https://opensource.facebook.com" target="_blank" rel="noopener noreferrer" class="footerLogoLink_MyFc"><img src="/Aria_data_tools/img/oss_logo.png" alt="Facebook Open Source Logo" class="themedImage_1VuW themedImage--light_3UqQ footer__logo"><img src="/Aria_data_tools/img/oss_logo.png" alt="Facebook Open Source Logo" class="themedImage_1VuW themedImage--dark_hz6m footer__logo"></a></div><div class="footer__copyright">Copyright Â© 2022 Meta Platforms, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/Aria_data_tools/assets/js/runtime~main.78e34e17.js"></script>
<script src="/Aria_data_tools/assets/js/main.dd0e5fb6.js"></script>
</body>
</html>