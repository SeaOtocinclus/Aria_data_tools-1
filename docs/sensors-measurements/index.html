<!doctype html>
<html class="docs-version-current" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.6">
<title data-react-helmet="true">Sensors and Measurements | Aria Data Tools</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://facebookresearch.github.io/Aria_data_tools/docs/sensors-measurements/"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="Sensors and Measurements | Aria Data Tools"><meta data-react-helmet="true" name="description" content="Introduction"><meta data-react-helmet="true" property="og:description" content="Introduction"><link data-react-helmet="true" rel="shortcut icon" href="/Aria_data_tools/img/fav_aria_icon.png"><link data-react-helmet="true" rel="canonical" href="https://facebookresearch.github.io/Aria_data_tools/docs/sensors-measurements/"><link data-react-helmet="true" rel="alternate" href="https://facebookresearch.github.io/Aria_data_tools/docs/sensors-measurements/" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://facebookresearch.github.io/Aria_data_tools/docs/sensors-measurements/" hreflang="x-default"><link rel="stylesheet" href="/Aria_data_tools/assets/css/styles.7603c748.css">
<link rel="preload" href="/Aria_data_tools/assets/js/runtime~main.78e34e17.js" as="script">
<link rel="preload" href="/Aria_data_tools/assets/js/main.dd0e5fb6.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script>
<div style="display: none; text-align: center; background-color: white; color: black;" id="internaldocs-banner"></div><div id="__docusaurus">
<div><a href="#" class="skipToContent_1oUP">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Aria_data_tools/"><img src="/Aria_data_tools/img/glasses-solid.svg" alt="aria-research-kit-sdk Logo" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/Aria_data_tools/img/glasses-solid.svg" alt="aria-research-kit-sdk Logo" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"><b class="navbar__title">Aria Data Tools</b></a><a class="navbar__item navbar__link navbar__link--active" href="/Aria_data_tools/docs/overview/">Documentation</a><a href="https://about.facebook.com/realitylabs/projectaria/datasets" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>Aria Pilot Dataset<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><a href="https://about.facebook.com/realitylabs/projectaria/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>Project Aria<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/facebookresearch/aria_data_tools" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="react-toggle toggle_3Zt9 react-toggle--disabled"><div class="react-toggle-track" role="button" tabindex="-1"><div class="react-toggle-track-check"><span class="toggle_71bT">ðŸŒœ</span></div><div class="react-toggle-track-x"><span class="toggle_71bT">ðŸŒž</span></div><div class="react-toggle-thumb"></div></div><input type="checkbox" class="react-toggle-screenreader-only" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_31aa"><button class="clean-btn backToTopButton_35hR" type="button"><svg viewBox="0 0 24 24" width="28"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z" fill="currentColor"></path></svg></button><aside class="docSidebarContainer_3Kbt"><div class="sidebar_15mo"><nav class="menu thin-scrollbar menu_Bmed menuWithAnnouncementBar_2WvA"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" href="/Aria_data_tools/docs/overview/">Overview</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" href="/Aria_data_tools/docs/Install/">Install</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/Aria_data_tools/docs/sensors-measurements/">Sensors and Measurements</a></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#">How to Use the Tools</a></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#">Aria Pilot Dataset</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" href="/Aria_data_tools/docs/aria-vrs/">How Project Aria Uses VRS</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" href="/Aria_data_tools/docs/use-vrs/">Getting to Know and Use VRS</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" href="/Aria_data_tools/docs/faq/">FAQ</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" href="/Aria_data_tools/docs/citation-contribute/">Citation and Contributing</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" href="/Aria_data_tools/docs/license/">License</a></li></ul></nav></div></aside><main class="docMainContainer_3ufF"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_1lV3"><div class="docItemContainer_zt2Y"><article><div class="markdown"><header><h1>Sensors and Measurements</h1></header><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="introduction"></a>Introduction<a class="hash-link" href="#introduction" title="Direct link to heading">#</a></h2><p>This page provides an overview of the sensors and measurements we use for Project Aria, covering:</p><ul><li>Project Aria device sensors</li><li>Naming conventions for all the tools and IDs used for sensors</li><li>Coordinate systems</li><li>Time (inc time stamping and camera shutter types)</li><li>Units of measurement</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="sensors"></a>Sensors<a class="hash-link" href="#sensors" title="Direct link to heading">#</a></h2><p>Project Aria sensor data is stored in <a href="https://facebookresearch.github.io/vrs/docs/Overview" target="_blank" rel="noopener noreferrer">VRS</a> and can record with:</p><ul><li>1 x 110 degree HFOV Rolling Shutter High Resolution RGB camera, up to 8MP</li><li>2 x 150 HFOV / 120 degree VFOV Global Shutter mono cameras for SLAM &amp; hand tracking, 640 x 480 pix</li><li>2 x 80 degree DFOV Eye-tracking Global Shutter mono cameras with IR illumination, 320 x 240 pix</li><li>2 x IMU, Barometer and Magnetometer (one IMU is 1KHz and the other is 800Hz)</li><li>7 x 48 KHz spatial microphones</li><li>GPS, Bluetooth and WiFi</li></ul><p>Researchers can use different sensor profiles when collecting data. Sensor profiles allow them to choose which sensors record as well as what settings to use. Settings options include what camera resolution to use and whether the output is RAW (no encoding) or JPEG (compressed).</p><div class="admonition admonition-note alert alert--secondary"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</h5></div><div class="admonition-content"><p>Cameras on Project Aria devices are installed sideways. By default, images are reported and viewed as they were provided by cameras and will appear sideways.</p></div></div><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="naming-conventions-for-all-tools"></a>Naming conventions for all tools<a class="hash-link" href="#naming-conventions-for-all-tools" title="Direct link to heading">#</a></h2><p>We use the sensor name set as the main query type for each sensor in all tools. The naming conventions for all sensors are:</p><ul><li>Cameras: camera-slam-left, camera-slam-right, camera-et-left, camera-et-right, camera-rgb</li><li>IMUs: imu-left, imu-right</li><li>Magnetometers: mag0</li><li>Microphones: mic0, mic1, ..., mic6</li><li>Barometer: baro0</li></ul><p>Each sensor is associated with an instance-invariant name. For example, the left SLAM camera is named as &quot;camera-slam-left&quot;. The name set of supported sensors can be fetched in Python3 with the <code>deviceModel.getCameraLabels()</code> command:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">&gt;&gt;&gt; deviceModel.getCameraLabels()</span></span><span class="token-line" style="color:#393A34"><span class="token plain">[&#x27;camera-et-left&#x27;, &#x27;camera-et-right&#x27;, &#x27;camera-rgb&#x27;, &#x27;camera-slam-left&#x27;, &#x27;camera-slam-right&#x27;]</span></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;&gt;&gt; deviceModel.getImuLabels()</span></span><span class="token-line" style="color:#393A34"><span class="token plain">[&#x27;imu-left&#x27;, &#x27;imu-right&#x27;]`</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><div class="admonition admonition-note alert alert--secondary"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</h5></div><div class="admonition-content"><p>Left/Right are relative to the left and right side of the glasses when the user is wearing the device. Another way to differentiate between the two sides is that the left SLAM camera is closer to the RGB camera.</p></div></div><p><strong>Table 1:</strong> <em>IDs Used for Sensors</em></p><table><thead><tr><th>StreamId</th><th>Stream</th><th>vrs::RecordableTypeId</th><th>VRS Instance ID</th><th>Calibration labels for coordinate transform</th><th>DataProvider API</th></tr></thead><tbody><tr><td>211-1</td><td>Eye tracking camera</td><td>EyeCameraRecordableClass (211)</td><td>1</td><td><code>camera-et-left</code> <code>camera-et-right</code></td><td>getEyeCameraPlayer()</td></tr><tr><td>214-1</td><td>RGB camera</td><td>RgbCameraRecordableClass (214)</td><td>1</td><td><code>camera-rgb</code></td><td>getRgbCameraPlayer()</td></tr><tr><td>231-1</td><td>Microphones</td><td>StereoAudioRecordableClass (231)</td><td>1</td><td><code>mic0</code>, <code>mic1</code>, <code>mic2</code>, ..., <code>mic6</code></td><td>getAudioPlayer()</td></tr><tr><td>247-1</td><td>Barometer</td><td>BarometerRecordableClass (247)</td><td>1</td><td><code>baro0</code></td><td>getBarometerPlayer()</td></tr><tr><td>281-1</td><td>GPS</td><td>GpsRecordableClass (281)</td><td>1</td><td></td><td>getGpsPlayer()</td></tr><tr><td>283-1</td><td>Bluetooth beacon</td><td>BluetoothBeaconRecordableClass (283)</td><td>1</td><td></td><td>getBluetoothBeaconPlayer()</td></tr><tr><td>285-1</td><td>Time domain</td><td>TimeRecordableClass (285)</td><td>1</td><td></td><td>getTimeSyncPlayer()</td></tr><tr><td>1201-1</td><td>SLAM Camera Left</td><td>SlamCameraData (1201)</td><td>1</td><td><code>camera-slam-left</code></td><td>getSlamLeftCameraPlayer()</td></tr><tr><td>1201-2</td><td>SLAM Camera Right</td><td>SlamCameraData (1201)</td><td>2</td><td><code>camera-slam-right</code></td><td>getSlamRightCameraPlayer()</td></tr><tr><td>1202-1</td><td>IMU sensor 1 (1KHz)</td><td>SlamImuData (1202)</td><td>1</td><td><code>imu-right</code></td><td>getImuRightPlayer()</td></tr><tr><td>1202-2</td><td>IMU sensor 2 (800Hz)</td><td>SlamImuData (1202)</td><td>2</td><td><code>imu-left</code></td><td>getImuLeftPlayer()</td></tr><tr><td>1203-1</td><td>Magnetometer</td><td>SlamMagnetometerData (1203)</td><td>1</td><td><code>mag0</code></td><td>getMagnetometerPlayer()</td></tr></tbody></table><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="recordabletypeid"></a>RecordableTypeId<a class="hash-link" href="#recordabletypeid" title="Direct link to heading">#</a></h3><p>VRS files contain multiple streams, each associated with a device type, defined by a <a href="https://github.com/facebookresearch/vrs/blob/main/vrs/StreamId.h" target="_blank" rel="noopener noreferrer"><code>RecordableTypeId</code></a> enum value. For Project Aria, each kind of sensor is defined as a device type. See <a href="https://facebookresearch.github.io/vrs/docs/FileStructure#streams" target="_blank" rel="noopener noreferrer">Streams</a> in VRS&#x27;s Documentation for more information.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="vrs-instance-id"></a>VRS instance ID<a class="hash-link" href="#vrs-instance-id" title="Direct link to heading">#</a></h3><p>A unique ID number for each instance of a sensor type. The first instance of a sensor type has the number 1, the second sensor number 2, and so on.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="streamid"></a>StreamId<a class="hash-link" href="#streamid" title="Direct link to heading">#</a></h3><p>Unique identifier for a stream of data in VRS.</p><p>A StreamId identifies each instance of a sensor, device, algorithm, or &quot;something&quot; that produces a stream of records. A StreamId combines a RecordableTypeId that describes the type of sensor device, or other producer of records, and an instance id, to differentiate streams coming from different sensors of the same type.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="coordinate-systems"></a>Coordinate Systems<a class="hash-link" href="#coordinate-systems" title="Direct link to heading">#</a></h2><p>Applications like stereo vision and navigation usually handle 2D and 3D points in different spaces, and transformations need to be conducted between them. With Project Aria data, we attach a local R3 coordinate frame to each sensor.</p><p><img alt="image of aria device with all the sensors" src="/Aria_data_tools/assets/images/aria_ref_frames_all_black-3c9d0c2f0c7717d0e9a9d9912aa93ce7.png"></p><p><strong>Figure 1:</strong> <em>Sensors and Sensor Directions on Project Aria Devices</em></p><p>See <a href="/Aria_data_tools/docs/howto/calibration/">Calibration Sensor Data</a> for more information and code snippets.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="time"></a>Time<a class="hash-link" href="#time" title="Direct link to heading">#</a></h2><p>Every signal (or Record in VRS terms) collected by sensors is stamped with a timestamp from a common clock. For Project Aria data, this is usually the local time clock. All records are sorted in monotonically increasing order in a VRS file. We use the following sensor-specific conventions on timestamps:</p><ul><li>For all cameras, the timestamp of a frame is the center of exposure time, a.k.a. the middle point of exposure interval.</li><li>The RGB camera is a rolling shutter, with a readout time of 5ms (when recording at 1408x1408) or 15ms (when recording at 2880x2880) from first to last line. The recorded timestamp of an RGB frame is the center of exposure timestamp of the middle row of the image. SLAM and eye tracking cameras are global shutter and all of the pixels in the image are exposed simultaneously.</li><li>IMUs, accelerometers and gyroscopes may have a time offset from the local time clock. This is due to internal signal processing in the IMU, which introduces a small time delay. These are estimated during calibration and stored in the JSON as <code>TimeOffsetSec_Device_Gyro</code> and <code>TimeOffsetSec_Device_Accel</code> respectively.</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="units-of-measurement"></a>Units of Measurement<a class="hash-link" href="#units-of-measurement" title="Direct link to heading">#</a></h2><p>The units for numerical values in the code and documentation are:</p><ul><li>Coordinates, location and distance in world space: meters (m)</li><li>Coordinates in image space: pixels</li><li>Timestamp and time intervals: seconds (s)</li><li>Angles: radians (rad)</li><li>Acceleration: m/s^2</li><li>Angular velocity: rad/s</li><li>Pressure: pascal (Pa)</li><li>Temperature: celsius (Â°C)</li><li>Magnetometer: Tesla (T)</li></ul></div></article><div class="margin-vert--lg"><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/Aria_data_tools/docs/Install/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Â« Install</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/Aria_data_tools/docs/howto/examples/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Examples Â»</div></a></div></nav></div></div></div><div class="col col--3"><div class="tableOfContents_35-E thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction" class="table-of-contents__link">Introduction</a></li><li><a href="#sensors" class="table-of-contents__link">Sensors</a></li><li><a href="#naming-conventions-for-all-tools" class="table-of-contents__link">Naming conventions for all tools</a><ul><li><a href="#recordabletypeid" class="table-of-contents__link">RecordableTypeId</a></li><li><a href="#vrs-instance-id" class="table-of-contents__link">VRS instance ID</a></li><li><a href="#streamid" class="table-of-contents__link">StreamId</a></li></ul></li><li><a href="#coordinate-systems" class="table-of-contents__link">Coordinate Systems</a></li><li><a href="#time" class="table-of-contents__link">Time</a></li><li><a href="#units-of-measurement" class="table-of-contents__link">Units of Measurement</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Learn</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/Aria_data_tools/docs/overview/">Documentation</a></li></ul></div><div class="col footer__col"><div class="footer__title">Project Aria</div><ul class="footer__items"><li class="footer__item"><a href="https://about.facebook.com/realitylabs/projectaria/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Introducing Project Aria<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://about.facebook.com/realitylabs/projectaria/datasets" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Aria Pilot Dataset<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">Responsible Innovation</div><ul class="footer__items"><li class="footer__item"><a href="https://about.facebook.com/realitylabs/responsible-innovation-principles/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Responsible Innovation Principles<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://about.facebook.com/realitylabs/projectaria/community-guidelines/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Project Aria Research Community Guidelines<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="margin-bottom--sm"><a href="https://opensource.facebook.com" target="_blank" rel="noopener noreferrer" class="footerLogoLink_MyFc"><img src="/Aria_data_tools/img/oss_logo.png" alt="Facebook Open Source Logo" class="themedImage_1VuW themedImage--light_3UqQ footer__logo"><img src="/Aria_data_tools/img/oss_logo.png" alt="Facebook Open Source Logo" class="themedImage_1VuW themedImage--dark_hz6m footer__logo"></a></div><div class="footer__copyright">Copyright Â© 2022 Meta Platforms, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/Aria_data_tools/assets/js/runtime~main.78e34e17.js"></script>
<script src="/Aria_data_tools/assets/js/main.dd0e5fb6.js"></script>
</body>
</html>